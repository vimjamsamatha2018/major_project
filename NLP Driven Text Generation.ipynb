{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dE5mLcL9wAcz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v8Fq4DLbwSUs"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3yB5VcsEwVXa"
   },
   "outputs": [],
   "source": [
    "path_to_file = '/content/shakespeare.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "slarZfMkw-AG",
    "outputId": "3b9b6a12-251e-40bc-959c-1527a3dd8c3c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"\\n                     1\\n  From fairest creatures we desire increase,\\n  That thereby beauty's rose might never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou contracted to thine own bright eyes,\\n  Feed'st thy light's flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thy self thy foe, to thy sweet self too cruel:\\n  Thou that art now the world's fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bu\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = open(path_to_file,'r').read()\n",
    "text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tSInsAG-xIVf",
    "outputId": "efc6853a-ea30-4f89-f49f-d1a8106143d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bu\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vbQrmVIwxRP1",
    "outputId": "eb5092a0-2320-4e99-c40d-26852c1b353d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '>',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " ']',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '|',\n",
       " '}']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(set(text)) # gives us all the unique characters\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kf1BXhWcxjTX",
    "outputId": "61bb96c9-7cb2-4e1f-e9f4-5822a6ad2e35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab) # we have 84 UNIQUE characters in this text dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "9d8iRvRYxxC2",
    "outputId": "56731b8a-f90d-4a7d-aaf8-f86afbe8bfc0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nfor pair in enumerate(vocab): # enumerate returns index values for each character\\n  print(pair)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for pair in enumerate(vocab): # enumerate returns index values for each character\n",
    "  print(pair)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ch2QZTNW05cB"
   },
   "source": [
    "### Now we will use the above cell block to make a dictionary with the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kTTpe8iw1Bi0",
    "outputId": "ac27607f-9ac5-48b2-f120-943c9a3f081e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '\"': 3,\n",
       " '&': 4,\n",
       " \"'\": 5,\n",
       " '(': 6,\n",
       " ')': 7,\n",
       " ',': 8,\n",
       " '-': 9,\n",
       " '.': 10,\n",
       " '0': 11,\n",
       " '1': 12,\n",
       " '2': 13,\n",
       " '3': 14,\n",
       " '4': 15,\n",
       " '5': 16,\n",
       " '6': 17,\n",
       " '7': 18,\n",
       " '8': 19,\n",
       " '9': 20,\n",
       " ':': 21,\n",
       " ';': 22,\n",
       " '<': 23,\n",
       " '>': 24,\n",
       " '?': 25,\n",
       " 'A': 26,\n",
       " 'B': 27,\n",
       " 'C': 28,\n",
       " 'D': 29,\n",
       " 'E': 30,\n",
       " 'F': 31,\n",
       " 'G': 32,\n",
       " 'H': 33,\n",
       " 'I': 34,\n",
       " 'J': 35,\n",
       " 'K': 36,\n",
       " 'L': 37,\n",
       " 'M': 38,\n",
       " 'N': 39,\n",
       " 'O': 40,\n",
       " 'P': 41,\n",
       " 'Q': 42,\n",
       " 'R': 43,\n",
       " 'S': 44,\n",
       " 'T': 45,\n",
       " 'U': 46,\n",
       " 'V': 47,\n",
       " 'W': 48,\n",
       " 'X': 49,\n",
       " 'Y': 50,\n",
       " 'Z': 51,\n",
       " '[': 52,\n",
       " ']': 53,\n",
       " '_': 54,\n",
       " '`': 55,\n",
       " 'a': 56,\n",
       " 'b': 57,\n",
       " 'c': 58,\n",
       " 'd': 59,\n",
       " 'e': 60,\n",
       " 'f': 61,\n",
       " 'g': 62,\n",
       " 'h': 63,\n",
       " 'i': 64,\n",
       " 'j': 65,\n",
       " 'k': 66,\n",
       " 'l': 67,\n",
       " 'm': 68,\n",
       " 'n': 69,\n",
       " 'o': 70,\n",
       " 'p': 71,\n",
       " 'q': 72,\n",
       " 'r': 73,\n",
       " 's': 74,\n",
       " 't': 75,\n",
       " 'u': 76,\n",
       " 'v': 77,\n",
       " 'w': 78,\n",
       " 'x': 79,\n",
       " 'y': 80,\n",
       " 'z': 81,\n",
       " '|': 82,\n",
       " '}': 83}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ind = {char:ind for ind,char in enumerate(vocab)}\n",
    "char_to_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Tm8jvdt1MLy",
    "outputId": "4b61d261-8e7f-4bae-b1d3-aeaa1ef38089"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ind['v'] #gives us the numeric index for the character 'v'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJHxA1yi1ish"
   },
   "source": [
    "## We made a function to give indexes to each character...but now we want to pass in the index number and get the character at that index, so we will do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fzzO1fdV1X7A"
   },
   "outputs": [],
   "source": [
    "ind_to_char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "jwPnCkX-1fie",
    "outputId": "dc219ae8-28c7-4fb8-8542-8106f1f75ecc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'H'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_to_char[33] # 'H' is at index position 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30-T8rI61g57"
   },
   "outputs": [],
   "source": [
    "encoded_text = np.array([char_to_ind[c] for c in text])\n",
    "# this line will encode everything in the shakespear text file into a numpy array AKA NUMERIC VALUE FOR EVERY WORD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jLb7kg6w2ErW",
    "outputId": "0ce4fdde-b9a2-44f6-8d57-9db330fd2475"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  1, ..., 30, 39, 29])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u36Wf8ks2IE_",
    "outputId": "e7d6952b-ae1e-43a3-9838-2a4eeedd4484"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5445609,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text.shape # 5.5 MILLION CHARACTERS IN OUR FILE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "0hNHYXhD2LZH",
    "outputId": "741f05c0-edb1-42e0-b6b6-cc311bf5a2aa"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"\\n                     1\\n  From fairest creatures we desire increase,\\n  That thereby beauty's rose might never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou contracted to thine own bright eyes,\\n  Feed'st thy light's flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thy self thy foe, to thy sweet self too cruel:\\n  Thou that art now the world's fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bu\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = text[:500]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PbAhYIsi2aTQ",
    "outputId": "1714b6cb-f91a-4578-e35f-ca4bf49f3910"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1, 12,  0,  1,  1, 31, 73, 70, 68,  1, 61, 56, 64,\n",
       "       73, 60, 74, 75,  1, 58, 73, 60, 56, 75, 76, 73, 60, 74,  1, 78, 60,\n",
       "        1, 59, 60, 74, 64, 73, 60,  1, 64, 69, 58, 73, 60, 56, 74, 60,  8,\n",
       "        0,  1,  1, 45, 63, 56, 75,  1, 75, 63, 60, 73, 60, 57, 80,  1, 57,\n",
       "       60, 56, 76, 75, 80,  5, 74,  1, 73, 70, 74, 60,  1, 68, 64, 62, 63,\n",
       "       75,  1, 69, 60, 77, 60, 73,  1, 59, 64, 60,  8,  0,  1,  1, 27, 76,\n",
       "       75,  1, 56, 74,  1, 75, 63, 60,  1, 73, 64, 71, 60, 73,  1, 74, 63,\n",
       "       70, 76, 67, 59,  1, 57, 80,  1, 75, 64, 68, 60,  1, 59, 60, 58, 60,\n",
       "       56, 74, 60,  8,  0,  1,  1, 33, 64, 74,  1, 75, 60, 69, 59, 60, 73,\n",
       "        1, 63, 60, 64, 73,  1, 68, 64, 62, 63, 75,  1, 57, 60, 56, 73,  1,\n",
       "       63, 64, 74,  1, 68, 60, 68, 70, 73, 80, 21,  0,  1,  1, 27, 76, 75,\n",
       "        1, 75, 63, 70, 76,  1, 58, 70, 69, 75, 73, 56, 58, 75, 60, 59,  1,\n",
       "       75, 70,  1, 75, 63, 64, 69, 60,  1, 70, 78, 69,  1, 57, 73, 64, 62,\n",
       "       63, 75,  1, 60, 80, 60, 74,  8,  0,  1,  1, 31, 60, 60, 59,  5, 74,\n",
       "       75,  1, 75, 63, 80,  1, 67, 64, 62, 63, 75,  5, 74,  1, 61, 67, 56,\n",
       "       68, 60,  1, 78, 64, 75, 63,  1, 74, 60, 67, 61,  9, 74, 76, 57, 74,\n",
       "       75, 56, 69, 75, 64, 56, 67,  1, 61, 76, 60, 67,  8,  0,  1,  1, 38,\n",
       "       56, 66, 64, 69, 62,  1, 56,  1, 61, 56, 68, 64, 69, 60,  1, 78, 63,\n",
       "       60, 73, 60,  1, 56, 57, 76, 69, 59, 56, 69, 58, 60,  1, 67, 64, 60,\n",
       "       74,  8,  0,  1,  1, 45, 63, 80,  1, 74, 60, 67, 61,  1, 75, 63, 80,\n",
       "        1, 61, 70, 60,  8,  1, 75, 70,  1, 75, 63, 80,  1, 74, 78, 60, 60,\n",
       "       75,  1, 74, 60, 67, 61,  1, 75, 70, 70,  1, 58, 73, 76, 60, 67, 21,\n",
       "        0,  1,  1, 45, 63, 70, 76,  1, 75, 63, 56, 75,  1, 56, 73, 75,  1,\n",
       "       69, 70, 78,  1, 75, 63, 60,  1, 78, 70, 73, 67, 59,  5, 74,  1, 61,\n",
       "       73, 60, 74, 63,  1, 70, 73, 69, 56, 68, 60, 69, 75,  8,  0,  1,  1,\n",
       "       26, 69, 59,  1, 70, 69, 67, 80,  1, 63, 60, 73, 56, 67, 59,  1, 75,\n",
       "       70,  1, 75, 63, 60,  1, 62, 56, 76, 59, 80,  1, 74, 71, 73, 64, 69,\n",
       "       62,  8,  0,  1,  1, 48, 64, 75, 63, 64, 69,  1, 75, 63, 64, 69, 60,\n",
       "        1, 70, 78, 69,  1, 57, 76])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text[:500] #we see how this returns every word in its NUMERIC FORM which helps the machine to read+understand it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GqOMBTFM2eAb"
   },
   "source": [
    "#NOW WE WILL CREATE BATCHES FROM THE TEXT DATA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VR6cxW37bvl0",
    "outputId": "88228a4a-a2c2-4ce3-ef83-4b89a94b19ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bu\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9s_1R5z5c3p9",
    "outputId": "ea47ad84-8691-45ad-9883-853e4ffad349"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we take the first line form the text data and check its length\n",
    "line = \"From fairest creatures we desire increase\"\n",
    "len(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xyTN3HbddVrt"
   },
   "source": [
    "# We are doing all this to make sure we choose the correct sequence length\n",
    "- **We take 3 lines below because Shakespeare makes sure to rhyme at the end of every other line, so the model might need atleast 3 lines worth of text data to make accurate predictions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKmUABjic9sT"
   },
   "outputs": [],
   "source": [
    "# we take the first 3 lines and check their length\n",
    "lines = '''\n",
    "From fairest creatures we desire increase,\n",
    "  That thereby beauty's rose might never die,\n",
    "  But as the riper should by time decease,\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZCRfZn6cdcph",
    "outputId": "fd495bc8-f889-446a-c026-955fb7f2bab5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rkTTv6nxddps"
   },
   "outputs": [],
   "source": [
    "seq_len = 120 # WE TAKE SEQUENCE LENGTH OF 120 BECAUSE THAT SEEMS SUFFICIENT FOR THE MODEL TO UNDERSTAND THE TEXT DATA AND MAKE ACCURATE PREDICTIONS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DyilhYsfeAhS"
   },
   "outputs": [],
   "source": [
    "total_num_seq = len(text) // (seq_len+1) #we use '//' instead of '/' because '/' will return not-rounded number while '//' returns a rounded number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BI8xfT3tezGb"
   },
   "source": [
    "#**IMPORTANT NOTE** : We do +1 here because later in the code we ask for the first word or the 'word number 1' but as python starts the indexing at 0, we need to add 1 so that there is no error there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-x18jFdCe8Qv",
    "outputId": "6bd8c11f-09c2-480a-ec57-58eae26f2bfe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45005"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_num_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h3ePzkjae_Lb"
   },
   "outputs": [],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n",
    "# read about 'tf.data.Dataset.from_tensor_slices()' function if you have any doubts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lqPPkRkxfzl8",
    "outputId": "f455791b-b039-4cd0-8d5c-b7151a5f1dde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(char_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vBUlUSjOf9qN",
    "outputId": "3fae6156-6fc4-416e-86ff-4947c20f9b54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "1\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "F\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "f\n",
      "a\n",
      "i\n",
      "r\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "c\n",
      "r\n",
      "e\n",
      "a\n",
      "t\n",
      "u\n",
      "r\n",
      "e\n",
      "s\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "d\n",
      "e\n",
      "s\n",
      "i\n",
      "r\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "c\n",
      "r\n",
      "e\n",
      "a\n",
      "s\n",
      "e\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "T\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      "b\n",
      "y\n",
      " \n",
      "b\n",
      "e\n",
      "a\n",
      "u\n",
      "t\n",
      "y\n",
      "'\n",
      "s\n",
      " \n",
      "r\n",
      "o\n",
      "s\n",
      "e\n",
      " \n",
      "m\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n",
      " \n",
      "n\n",
      "e\n",
      "v\n",
      "e\n",
      "r\n",
      " \n",
      "d\n",
      "i\n",
      "e\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "B\n",
      "u\n",
      "t\n",
      " \n",
      "a\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "r\n",
      "i\n",
      "p\n",
      "e\n",
      "r\n",
      " \n",
      "s\n",
      "h\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      " \n",
      "b\n",
      "y\n",
      " \n",
      "t\n",
      "i\n",
      "m\n",
      "e\n",
      " \n",
      "d\n",
      "e\n",
      "c\n",
      "e\n",
      "a\n",
      "s\n",
      "e\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "H\n",
      "i\n",
      "s\n",
      " \n",
      "t\n",
      "e\n",
      "n\n",
      "d\n",
      "e\n",
      "r\n",
      " \n",
      "h\n",
      "e\n",
      "i\n",
      "r\n",
      " \n",
      "m\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n",
      " \n",
      "b\n",
      "e\n",
      "a\n",
      "r\n",
      " \n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "m\n",
      "e\n",
      "m\n",
      "o\n",
      "r\n",
      "y\n",
      ":\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "B\n",
      "u\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "o\n",
      "u\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "n\n",
      "e\n",
      " \n",
      "o\n",
      "w\n",
      "n\n",
      " \n",
      "b\n",
      "r\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n",
      " \n",
      "e\n",
      "y\n",
      "e\n",
      "s\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "F\n",
      "e\n",
      "e\n",
      "d\n",
      "'\n",
      "s\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "y\n",
      " \n",
      "l\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n",
      "'\n",
      "s\n",
      " \n",
      "f\n",
      "l\n",
      "a\n",
      "m\n",
      "e\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      "-\n",
      "s\n",
      "u\n",
      "b\n",
      "s\n",
      "t\n",
      "a\n",
      "n\n",
      "t\n",
      "i\n",
      "a\n",
      "l\n",
      " \n",
      "f\n",
      "u\n",
      "e\n",
      "l\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "M\n",
      "a\n",
      "k\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      " \n",
      "f\n",
      "a\n",
      "m\n",
      "i\n",
      "n\n",
      "e\n",
      " \n",
      "w\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "a\n",
      "b\n",
      "u\n",
      "n\n",
      "d\n",
      "a\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "l\n",
      "i\n",
      "e\n",
      "s\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "T\n",
      "h\n",
      "y\n",
      " \n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "y\n",
      " \n",
      "f\n",
      "o\n",
      "e\n",
      ",\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "y\n",
      " \n",
      "s\n",
      "w\n",
      "e\n",
      "e\n",
      "t\n",
      " \n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      " \n",
      "t\n",
      "o\n",
      "o\n",
      " \n",
      "c\n",
      "r\n",
      "u\n",
      "e\n",
      "l\n",
      ":\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "T\n",
      "h\n",
      "o\n",
      "u\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "a\n",
      "r\n",
      "t\n",
      " \n",
      "n\n",
      "o\n",
      "w\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "w\n",
      "o\n",
      "r\n",
      "l\n",
      "d\n",
      "'\n",
      "s\n",
      " \n",
      "f\n",
      "r\n",
      "e\n",
      "s\n",
      "h\n",
      " \n",
      "o\n",
      "r\n",
      "n\n",
      "a\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "A\n",
      "n\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      "l\n",
      "y\n",
      " \n",
      "h\n",
      "e\n",
      "r\n",
      "a\n",
      "l\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "g\n",
      "a\n",
      "u\n",
      "d\n",
      "y\n",
      " \n",
      "s\n",
      "p\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "W\n",
      "i\n",
      "t\n",
      "h\n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "n\n",
      "e\n",
      " \n",
      "o\n",
      "w\n",
      "n\n",
      " \n",
      "b\n",
      "u\n"
     ]
    }
   ],
   "source": [
    "#Creates a Dataset with at most count elements from this dataset\n",
    "for item in char_dataset.take(500):\n",
    "  print(ind_to_char[item.numpy()]) #this returns every alphabet individually from every word.\n",
    "\n",
    "#print(item.numpy()) returns numbers/indexes of every word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BRMIvIl6gayA"
   },
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(batch_size= seq_len+1, drop_remainder=True) #Combines consecutive elements of this dataset into batches.\n",
    "# As our dataset is NOT perfectly divisble by the number of sequences, it will leave a remainder, so we use drop_remainder=True to drop those values.\n",
    "# we will drop just 119 characters from a dataset containing 5M so it's ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3WZ-voBiv_T"
   },
   "outputs": [],
   "source": [
    "# given a sequence of length 120, the input_text starts from the beginning till the end excluding the last character.\n",
    "def create_seq_targets(seq):\n",
    "  input_txt = seq[:-1] # from index 0 uptil the end but not including the last character, eg- Hello my nam\n",
    "  target_txt = seq[1:] #from index 1 till the end, eg- ello my name aka we shift ahead by one character.\n",
    "  return input_txt, target_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hII_g1ePkAkQ"
   },
   "outputs": [],
   "source": [
    "dataset = sequences.map(create_seq_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hlol3hSikOoj",
    "outputId": "9033c1cc-751b-4533-9d94-8f8dc3b6882b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
      "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
      "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
      " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
      " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But\n",
      "\n",
      "\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
      "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
      " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
      " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
      "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But \n"
     ]
    }
   ],
   "source": [
    "for input_txt,target_txt in dataset.take(1):\n",
    "  print(input_txt.numpy())\n",
    "  print(\"\".join(ind_to_char[input_txt.numpy()]))\n",
    "  print('\\n')\n",
    "  print(target_txt.numpy())\n",
    "  print(\"\".join(ind_to_char[target_txt.numpy()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpJQiOlBlCHt"
   },
   "source": [
    "# What is happening above is that the model takes those numpy values of the words and understands the text that is below it for BOTH INPUT_TXT AND TARGET_TXT.\n",
    "- **The numbers and text that we see first is for the input_txt and then the next 2 is for the target_txt**\n",
    "- **We see that the target_txt starts from 1 and ends at 1 unlike the input_txt that starts at 0 and ends at 75 ; which means the target_txt is correctly shifting one step forward to the right.**\n",
    "- **The text looks the same above because the last character in the target_txt is a whitespace aka ' ' ; we can see this by selecting the whole input_txt and look at where the blue ends and then do the same for target_txt and see that there is an extra space while selecting it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2p1mh61Bl0ZO"
   },
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ML-kS8MJmWm2"
   },
   "outputs": [],
   "source": [
    "# WE SHUFFLE THE DATASET TO MAKE SURE THE MODEL DOESN'T JUST MEMORIZE A PARTICULAR SEQUENCE OF DATA\n",
    "\n",
    "buffer_size = 10000\n",
    "# Buffer size to shuffle the dataset so it doesn't attempt to shuffle\n",
    "# the entire sequence in memory. Instead, it maintains a buffer in which it shuffles elements\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size=buffer_size).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I15e0Dhtm8gS",
    "outputId": "0eb2c69c-e1b5-4b5c-a83b-4bfc26a8985b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((128, 120), (128, 120)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset\n",
    "# 128 different types of sequences where every sequence is 120 characters long; where the first (128,120) is for the input sequnce and the 2nd one is for the target sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dBU1Bzkm-BF"
   },
   "source": [
    "# CREATING THE MODEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yG9YykMxng2P"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab) #number of UNIQUE characters in this text dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CyuKrbranzOv",
    "outputId": "dfc0fa44-c747-4830-e93f-7a64fcaad7eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9aX3r9dpOfS"
   },
   "source": [
    "# NOTE: The embedding layer will serve as the input layer, which essentially creates a lookup table that maps the numbers indices of each character to a vector with \"embedding dim\" number of dimensions. As you can imagine, the larger this embedding size, the more complex the training. This is similar to the idea behind word2vec, where words are mapped to some n-dimensional space. Embedding before feeding straight into the LSTM usually leads to more realisitic results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7b7-vbKzn0A4"
   },
   "outputs": [],
   "source": [
    "embed_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cv60_JAOn5As"
   },
   "outputs": [],
   "source": [
    "rnn_neurons = 1026 # Number of RNN units; we just use a single leayer with a lot of neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgxaquk6pzm1"
   },
   "source": [
    "# SETTING UP THE LOSS FUNCTION:\n",
    "- **Why we use SPARSE:**\n",
    "\n",
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GLsB1JL9oBTx"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import sparse_categorical_crossentropy # WHY WE USE SPARSE IS SHOWN ABOVE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsBdWdjwqvrQ"
   },
   "source": [
    "# We will use an LSTM based model with a few extra features, including an embedding layer to start off with and two LSTM layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZihhCfiq1_Q"
   },
   "outputs": [],
   "source": [
    "# we create our custom loss function here to make sure from_logits=True bcz it should be true when we are ONE-HOT ENCODED WHICH WE ARE.\n",
    "def sparse_cat_loss(y_true,y_pred):\n",
    "  return sparse_categorical_crossentropy(y_true,y_pred, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDP8AfZFrjJT"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout,GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AomathAHrv-h"
   },
   "outputs": [],
   "source": [
    "def create_model(vocab_size,embed_dim,rnn_neurons,batch_size):\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(input_dim=vocab_size, output_dim=embed_dim, batch_input_shape=[batch_size,None]))\n",
    "\n",
    "  model.add(GRU(units=rnn_neurons, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'))\n",
    "  #NOW WE ADD OUR FINAL DENSE LAYER:\n",
    "  model.add(Dense(vocab_size))\n",
    "\n",
    "  model.compile('adam', loss=sparse_cat_loss)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2y8yj1a8tuu9"
   },
   "source": [
    "# Where vocab_size = 84, embed_dim = 64, rnn_neurons = 1026 and batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8W4WpPZttkSY"
   },
   "outputs": [],
   "source": [
    "model = create_model(vocab_size=vocab_size, embed_dim=embed_dim, rnn_neurons=rnn_neurons, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZjH_Jae6uB5x",
    "outputId": "a3b39b25-e3ef-490c-8756-4cbdf37e4b9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (128, None, 64)           5376      \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (128, None, 1026)         3361176   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (128, None, 84)           86268     \n",
      "=================================================================\n",
      "Total params: 3,452,820\n",
      "Trainable params: 3,452,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNcHdIzxuEfS"
   },
   "source": [
    "# TRAINING THE MODEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WIYB-4uyxRoC"
   },
   "outputs": [],
   "source": [
    "# just to check the model:\n",
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "\n",
    "  example_batch_preds = model(input_example_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "me3Y1za104-j",
    "outputId": "fb1030ab-9519-4a0c-ca86-e6324fcff51e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([128, 120, 84])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch_preds.shape # batch_size, sequence length, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K8u1Rpe609PP",
    "outputId": "7860eaae-5f10-4780-b2c6-f387abcaa7e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(120, 84), dtype=float32, numpy=\n",
       "array([[ 6.6124666e-03, -8.7229824e-03,  5.0702813e-04, ...,\n",
       "        -1.4054732e-03, -2.1066125e-03,  2.4682197e-03],\n",
       "       [ 7.1852417e-05, -8.4817940e-03, -3.4288496e-03, ...,\n",
       "        -3.8073899e-03, -2.0967738e-03,  7.2538727e-03],\n",
       "       [-1.4313087e-03, -8.1600053e-03, -5.8940179e-03, ...,\n",
       "         1.1522712e-03, -3.0179822e-04,  3.9321952e-03],\n",
       "       ...,\n",
       "       [ 1.5874643e-02, -1.4584118e-02, -4.5198817e-03, ...,\n",
       "        -3.4089843e-03,  8.5984990e-03,  4.9333940e-03],\n",
       "       [ 1.5358362e-02, -1.7029786e-02, -1.1033731e-04, ...,\n",
       "         2.2919145e-03,  1.2460375e-02, -7.2114402e-03],\n",
       "       [ 1.5506135e-02, -1.7657163e-02,  7.6683488e-04, ...,\n",
       "         9.1703964e-04,  2.1059928e-03, -3.9302534e-04]], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch_preds[0] # Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sYkpsHVb1EaS"
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_preds[0], num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9AN0yrX91UDL",
    "outputId": "ff0c7897-6d7c-4870-d6ff-0273780ffe1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42, 73, 13, 44, 25, 70, 21, 78, 73, 46,  4, 31, 69, 32, 35, 51, 43,\n",
       "       24, 15, 36, 45, 55, 24, 77,  9, 48, 13, 52, 80, 26, 48, 58,  6, 81,\n",
       "       70, 31, 26, 20, 53, 70, 63, 18, 18, 62, 61, 43, 21, 23, 44, 67, 30,\n",
       "       60, 58, 54, 57, 57, 56, 15,  2, 81, 82, 73, 38, 28,  8, 33,  3, 34,\n",
       "       37, 23,  3,  0, 44,  2, 72,  9, 17,  6, 60, 15, 83, 33, 30, 48, 26,\n",
       "        0,  5, 81, 13, 16, 29, 75, 66, 40, 47, 20, 29, 59, 30, 35, 47, 43,\n",
       "       42, 81, 15, 41, 20,  9,  7, 70, 12, 17, 42, 59, 56, 22, 41, 56,  8,\n",
       "       20])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy() #this reshapes it\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pxJErut51XgM",
    "outputId": "7e9b45e0-5d6b-47a9-fb20-e115744ab379"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Q', 'r', '2', 'S', '?', 'o', ':', 'w', 'r', 'U', '&', 'F', 'n',\n",
       "       'G', 'J', 'Z', 'R', '>', '4', 'K', 'T', '`', '>', 'v', '-', 'W',\n",
       "       '2', '[', 'y', 'A', 'W', 'c', '(', 'z', 'o', 'F', 'A', '9', ']',\n",
       "       'o', 'h', '7', '7', 'g', 'f', 'R', ':', '<', 'S', 'l', 'E', 'e',\n",
       "       'c', '_', 'b', 'b', 'a', '4', '!', 'z', '|', 'r', 'M', 'C', ',',\n",
       "       'H', '\"', 'I', 'L', '<', '\"', '\\n', 'S', '!', 'q', '-', '6', '(',\n",
       "       'e', '4', '}', 'H', 'E', 'W', 'A', '\\n', \"'\", 'z', '2', '5', 'D',\n",
       "       't', 'k', 'O', 'V', '9', 'D', 'd', 'E', 'J', 'V', 'R', 'Q', 'z',\n",
       "       '4', 'P', '9', '-', ')', 'o', '1', '6', 'Q', 'd', 'a', ';', 'P',\n",
       "       'a', ',', '9'], dtype='<U1')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_to_char[sampled_indices] #this is all random because the model hasnt been trained until now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDXY8-tz1rdf"
   },
   "outputs": [],
   "source": [
    "# THIS TOOK A LOT OF TIME, 1-2 MINS FOR EACH EPOCH, SO WE JUST LOAD THE MODEL PROVIDED BY UDEMY INSTEAD\n",
    "# epoch = 30\n",
    "# model.fit(dataset, epochs=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9NpkErY160L"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EBDxQ0Hs2Yl_"
   },
   "outputs": [],
   "source": [
    "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)\n",
    "\n",
    "model.load_weights('shakespeare_gen.h5') # we don't load the whole model, we just use its weights and train the model ourselves\n",
    "\n",
    "model.build(tf.TensorShape([1,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gqLiEZAb4cdb",
    "outputId": "515d6bb2-f4cf-4177-b315-9f44295cdce8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 64)             5376      \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1026)           3361176   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 84)             86268     \n",
      "=================================================================\n",
      "Total params: 3,452,820\n",
      "Trainable params: 3,452,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() #shape has changed from 128 previously to 1 now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7tKulISx4f0t"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_seed, gen_size=500, temp=1.0):\n",
    "  '''\n",
    "  model: Trained Model to Generate Text\n",
    "  start_seed: Intial Seed text in string form\n",
    "  gen_size: Number of characters to generate\n",
    "\n",
    "  Basic idea behind this function is to take in some seed text, format it so\n",
    "  that it is in the correct shape for our network, then loop the sequence as\n",
    "  we keep adding our own predicted characters. Similar to our work in the RNN\n",
    "  time series problems.\n",
    "  '''\n",
    "  # Number of characters to generate\n",
    "  num_generate = gen_size\n",
    "\n",
    "  input_eval = [char_to_ind[s] for s in start_seed] # Vectorizing starting seed text\n",
    "\n",
    "  input_eval = tf.expand_dims(input_eval,0) # Expand to match batch format shape\n",
    "\n",
    "  text_generated = [] # Empty list to hold resulting generated text\n",
    "\n",
    "  # Temperature effects randomness in our resulting text\n",
    "  # The term is derived from entropy/thermodynamics.\n",
    "  # The temperature is used to effect probability of next characters.\n",
    "  # Higher temperature == less surprising/ more expected\n",
    "  # Lower temperature == more surprising / less expected\n",
    "\n",
    "  temperature = temp\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "\n",
    "  for i in range(num_generate):\n",
    "    predictions = model(input_eval)\n",
    "    predictions = tf.squeeze(predictions,0)\n",
    "    predictions = predictions/temperature\n",
    "\n",
    "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "    input_eval = tf.expand_dims([predicted_id],0)\n",
    "\n",
    "    text_generated.append(ind_to_char[predicted_id])\n",
    "\n",
    "  return (start_seed+\"\".join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9eQKQ-G7hfg",
    "outputId": "3b376a1c-5172-47ba-ac97-c63b5365bc3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JULIETIDION. I am lost,\n",
      "    I will o'errung his melody in fliet\n",
      "    The heart that I had tricket daughter,\n",
      "    And cull it yours, although of power of suit,\n",
      "    Or rated me as it were, till this\n",
      "    plough's clothou.\n",
      "  CLOWN. Lady of England, when we abuse.\n",
      "  KING HENRY. Yes, faith, nor me; it goes unto rewarder.\n",
      "  KING EDWARD. Now, Sir Topas, sweet Brutus, take\n",
      "    me, and 'twere to much finely by my sorrow.\n",
      "  PAULINA. Then make a man-but furnish not a friendly\n",
      "    knave, i' faith, you are poor, is honest.\n",
      "    How now, spanish! How now! What is Jove runs\n",
      "    there?\n",
      "  FLAMIUS. Of that, milat, yet I'll ne'er acknowledg'd\n",
      "    to-morrow to a good wit, prick, but on executed pillow,\n",
      "    says but myself-\n",
      "    There is no face which I'll be well in land.\n",
      "  EXETER. What was the first coccofficene?  \n",
      "  TROILUS. Gramercian woe, for that the wonder even till this land,\n",
      "    Or else I swife, that I might were\n",
      "    That he's deliver'd to this gracious Dentlewoman?\n",
      "  SIRVANT. Sow with his son, these are the\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model,\"JULIET\",1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_u4SPsd75zj"
   },
   "source": [
    "# We can see that the model did a decent job at generating text that looks a lot like Shakespearen text. We can always try to improve the model by adding LSTM layers, playing around with other hyperparameters etc"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
